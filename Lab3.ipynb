{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b95d172b-b57e-40a3-8761-5c4989656932",
      "metadata": {
        "id": "b95d172b-b57e-40a3-8761-5c4989656932"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "469a23bd-5705-4ee7-a311-458b8dac89c8",
      "metadata": {
        "id": "469a23bd-5705-4ee7-a311-458b8dac89c8"
      },
      "outputs": [],
      "source": [
        "import torchvision.datasets\n",
        "MNIST_train = torchvision.datasets.MNIST('./', download=True, train=True)\n",
        "MNIST_test = torchvision.datasets.MNIST('./', download=True, train=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "922dfe42-898d-4895-8899-78ab91fca627",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "922dfe42-898d-4895-8899-78ab91fca627",
        "outputId": "2914fbf3-6ac0-4282-9ec3-800ebdfe77f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:62: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:52: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:67: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:57: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ]
        }
      ],
      "source": [
        "X_train = MNIST_train.train_data\n",
        "y_train = MNIST_train.train_labels\n",
        "X_test = MNIST_test.test_data\n",
        "y_test = MNIST_test.test_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d5711445-4aef-4b9b-8cb1-b606e3331e7f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5711445-4aef-4b9b-8cb1-b606e3331e7f",
        "outputId": "fb990031-b21c-49d4-e093-23e4bac8ea7a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.uint8, torch.int64)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "X_train.dtype, y_train.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0db92ebc-fea3-41f6-9d0c-a455cbb9a8ce",
      "metadata": {
        "id": "0db92ebc-fea3-41f6-9d0c-a455cbb9a8ce"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.float()\n",
        "X_test = X_test.float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5935f5c0-d567-44f4-8c44-d3e301e8441f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5935f5c0-d567-44f4-8c44-d3e301e8441f",
        "outputId": "991a03ac-0951-4b74-f723-2d6bc4f46387"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([60000, 28, 28]), torch.Size([10000, 28, 28]))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "42901169-39a9-4a44-9d1e-ab7014d894e1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42901169-39a9-4a44-9d1e-ab7014d894e1",
        "outputId": "dcfef6cc-948b-444d-fe0a-6b6fb62a9535"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([60000]), torch.Size([10000]))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f017ab38-63c5-478c-a3fd-9cb5c3f8486e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "f017ab38-63c5-478c-a3fd-9cb5c3f8486e",
        "outputId": "a58344d7-d566-446b-890c-b26895e60b9f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(5)\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(X_train[0, :, :])\n",
        "plt.show()\n",
        "print(y_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b20ad24b-a9d7-46dd-88b9-0124b3e1c49c",
      "metadata": {
        "id": "b20ad24b-a9d7-46dd-88b9-0124b3e1c49c"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.reshape([-1, 28 * 28])\n",
        "X_test = X_test.reshape([-1, 28 * 28])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "01b59a3c-633e-428e-afb2-94927856f443",
      "metadata": {
        "id": "01b59a3c-633e-428e-afb2-94927856f443"
      },
      "outputs": [],
      "source": [
        "class MNISTNet(torch.nn.Module): \n",
        "    def __init__(self, n_hidden_neurons): \n",
        "        super(MNISTNet, self).__init__() \n",
        "        self.fc1 = torch.nn.Linear(28 * 28, n_hidden_neurons) \n",
        "        self.ac1 = torch.nn.Sigmoid() \n",
        "        self.fc2 = torch.nn.Linear(n_hidden_neurons, 10) \n",
        "    def forward(self, x): \n",
        "        x = self.fc1(x) \n",
        "        x = self.ac1(x) \n",
        "        x = self.fc2(x) \n",
        "        return x \n",
        "mnist_net = MNISTNet(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a554410a-eee8-4a66-b392-23f13921db52",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a554410a-eee8-4a66-b392-23f13921db52",
        "outputId": "95493a7c-28fd-4f9c-defc-9179afcc030d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "eb6f8a57-c250-4764-8565-dd7c9d651510",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb6f8a57-c250-4764-8565-dd7c9d651510",
        "outputId": "7ce5bd2a-7e43-48bd-f0be-4796e37aaeb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Mar  7 14:55:09 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   72C    P8    32W / 149W |      3MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "device = torch.device('cuda:0')\n",
        "mnist_net = mnist_net.to(device)\n",
        "list(mnist_net.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQoKrbFX0-B3",
        "outputId": "b0b93f51-857d-40fd-a8c6-7ded08fd7f93"
      },
      "id": "IQoKrbFX0-B3",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.0003,  0.0192, -0.0294,  ...,  0.0219,  0.0037,  0.0021],\n",
              "         [-0.0198, -0.0150, -0.0104,  ..., -0.0203, -0.0060, -0.0299],\n",
              "         [-0.0201,  0.0149, -0.0333,  ..., -0.0203,  0.0012,  0.0080],\n",
              "         ...,\n",
              "         [ 0.0221,  0.0258, -0.0088,  ..., -0.0141,  0.0051, -0.0318],\n",
              "         [-0.0217, -0.0136,  0.0185,  ..., -0.0012, -0.0012, -0.0017],\n",
              "         [ 0.0142,  0.0089, -0.0053,  ...,  0.0311, -0.0181,  0.0020]],\n",
              "        device='cuda:0', requires_grad=True), Parameter containing:\n",
              " tensor([-3.5402e-02,  1.8178e-02, -2.1709e-02, -1.1839e-02,  4.8722e-03,\n",
              "         -1.0492e-02, -1.9008e-02,  2.6994e-02, -3.4899e-02,  1.0381e-02,\n",
              "         -3.5228e-02, -5.6381e-03, -2.0134e-02, -3.0264e-02, -1.3289e-02,\n",
              "          2.5346e-02, -1.0797e-02,  2.1568e-03,  4.3630e-03, -2.1916e-02,\n",
              "          2.2670e-02, -1.5766e-02,  3.4906e-02, -2.3063e-02, -6.8216e-03,\n",
              "          2.7051e-02, -1.3991e-02,  9.7218e-03, -9.9075e-04,  1.6625e-03,\n",
              "          2.3455e-02, -2.5294e-02,  4.8024e-06, -2.5339e-02, -1.7412e-02,\n",
              "         -1.6342e-02,  2.6164e-03, -1.8025e-02,  2.5939e-02,  2.3884e-03,\n",
              "          1.1857e-03, -2.0811e-03, -1.4417e-03,  2.2246e-02, -2.7703e-02,\n",
              "          1.9103e-02,  1.7750e-02, -4.5987e-03, -5.7228e-03,  1.1429e-02,\n",
              "         -1.9616e-02,  1.0336e-04,  2.3019e-02, -1.9994e-02,  1.5292e-03,\n",
              "         -3.4574e-02, -2.8799e-02,  1.0611e-02, -1.4141e-02, -2.3886e-02,\n",
              "          2.2307e-02, -3.0040e-02, -2.8897e-02, -9.2013e-03, -3.6146e-03,\n",
              "          3.4074e-03,  7.3265e-03, -1.7886e-02, -1.8164e-02, -1.9736e-02,\n",
              "         -3.0381e-02, -1.5204e-02,  2.4328e-02, -2.2534e-02,  4.2453e-04,\n",
              "          2.7948e-02,  1.3828e-03,  3.3543e-02, -3.3373e-02, -6.0236e-04,\n",
              "          1.1359e-02,  3.2776e-02, -3.6375e-03, -2.7758e-02, -4.0390e-03,\n",
              "         -1.8094e-03, -2.1388e-02,  1.8606e-03, -1.4006e-02, -2.9517e-02,\n",
              "         -1.6692e-02, -7.7352e-03, -1.9986e-02,  1.8643e-02, -2.0421e-02,\n",
              "          1.1466e-02, -2.7346e-02,  2.3264e-03, -3.3796e-02,  1.1720e-02],\n",
              "        device='cuda:0', requires_grad=True), Parameter containing:\n",
              " tensor([[-4.4030e-02, -4.0902e-02, -2.7658e-03, -7.5691e-02,  4.7223e-02,\n",
              "           2.0091e-02,  5.2066e-03,  2.9781e-02,  2.0557e-02, -3.9398e-02,\n",
              "          -4.3418e-02, -4.2620e-02,  2.0538e-02, -6.9487e-02, -1.0267e-03,\n",
              "           6.5385e-02, -2.4658e-03,  8.2882e-02,  5.6582e-02, -9.1259e-02,\n",
              "          -8.1402e-02,  9.4457e-02,  4.5791e-02, -9.5087e-02,  1.7097e-02,\n",
              "           4.3891e-02,  3.8794e-02,  2.8788e-02,  2.2401e-02, -6.5288e-02,\n",
              "           4.3317e-02,  2.0658e-02, -8.5607e-02, -5.5555e-02,  6.7581e-02,\n",
              "          -3.3979e-03,  9.5181e-02,  5.3261e-02, -5.3859e-02,  7.1806e-03,\n",
              "          -8.9716e-02, -5.7855e-02, -9.5984e-02, -8.0224e-02, -3.1562e-03,\n",
              "          -6.7034e-02, -9.0357e-02, -7.6925e-02, -8.4575e-02,  3.1875e-02,\n",
              "          -3.9122e-02,  2.7084e-02, -3.2642e-02, -3.9497e-02, -7.0178e-03,\n",
              "          -1.7398e-02,  5.8693e-02, -5.4878e-02,  4.2710e-02, -7.1184e-02,\n",
              "          -2.8224e-02, -4.4826e-02,  1.3082e-02,  4.7396e-02,  4.2165e-02,\n",
              "          -1.4485e-02,  6.3214e-02, -1.7163e-02, -5.6876e-02,  7.2040e-02,\n",
              "           4.9951e-02,  1.3729e-02,  1.6482e-02,  6.9580e-02, -8.0455e-03,\n",
              "           2.9021e-02,  5.1953e-03, -8.5754e-02, -7.1343e-02, -9.8854e-02,\n",
              "          -1.2864e-02, -8.1402e-02, -8.8800e-02, -7.0611e-02, -8.5149e-02,\n",
              "           2.2577e-02, -1.7917e-02,  3.4979e-02,  3.6967e-02,  2.0696e-03,\n",
              "          -4.5241e-02, -5.2543e-02,  8.7695e-02, -9.6897e-02, -4.1911e-02,\n",
              "           8.3253e-02,  1.9033e-02,  8.5772e-02, -9.1113e-02, -4.6074e-02],\n",
              "         [ 2.8562e-02, -9.7789e-02,  9.9616e-02,  1.0313e-02,  1.8937e-03,\n",
              "          -2.8054e-02,  5.7647e-02,  7.5185e-03, -7.6182e-02,  4.7473e-02,\n",
              "           9.2353e-02,  8.7539e-02,  4.3655e-02, -8.8865e-02,  5.0226e-02,\n",
              "           2.9909e-02, -9.6574e-02, -3.5466e-02, -9.3904e-02, -4.4798e-02,\n",
              "          -3.3621e-02, -6.5826e-02,  3.6287e-02, -3.3913e-02, -8.2384e-02,\n",
              "          -8.0630e-02, -3.6251e-02,  3.2257e-02, -1.7082e-02,  6.7202e-03,\n",
              "           4.9823e-02,  8.7775e-02, -5.6468e-02,  9.9253e-02,  9.1745e-02,\n",
              "           6.8144e-02,  6.4052e-02,  4.7919e-02, -9.1159e-02,  6.4923e-02,\n",
              "           6.1755e-04,  2.4259e-02, -5.2861e-02, -8.0466e-02, -7.4763e-02,\n",
              "          -2.4290e-02,  8.2725e-02, -5.2735e-02, -1.6988e-02,  8.4985e-03,\n",
              "          -6.6479e-02, -6.3317e-02,  2.7013e-02,  7.6525e-02, -9.6293e-02,\n",
              "          -2.3882e-02, -2.4638e-02, -1.5677e-02,  8.6723e-02,  1.1229e-02,\n",
              "          -3.8456e-02, -9.1262e-03, -1.0519e-02, -9.5751e-02, -1.0230e-02,\n",
              "           2.0495e-02,  1.0166e-02,  1.6618e-02, -7.6543e-02, -1.9185e-02,\n",
              "           3.6591e-03, -4.8461e-02, -3.9484e-02,  4.6251e-02,  6.8032e-02,\n",
              "          -6.6524e-02, -1.0022e-02, -4.8116e-02, -9.9494e-02, -7.2708e-02,\n",
              "           4.8695e-02, -5.4311e-02,  5.3059e-02, -5.1349e-02, -5.3362e-02,\n",
              "           5.6112e-04,  5.6536e-02,  7.5848e-02,  8.7638e-02, -2.6691e-02,\n",
              "           5.4360e-02, -9.7876e-02, -2.8115e-03,  7.7884e-03,  7.6152e-03,\n",
              "           2.9289e-02,  5.4671e-02,  6.9147e-02, -2.9804e-03, -5.5532e-02],\n",
              "         [-5.8062e-02, -1.6233e-02,  5.9640e-02,  3.8012e-02, -7.7325e-02,\n",
              "           5.2889e-02,  4.9676e-02, -8.6207e-02,  1.2076e-02, -6.6163e-02,\n",
              "          -8.3880e-02,  1.7198e-02, -3.7479e-02,  8.4232e-02, -5.0198e-02,\n",
              "           2.3431e-02, -2.2310e-02, -6.4360e-02, -2.8851e-02,  3.1953e-02,\n",
              "           3.2718e-02, -1.6766e-02, -9.4292e-02, -1.6340e-02,  4.0565e-02,\n",
              "          -5.5432e-02,  4.2336e-02,  9.1535e-02, -7.2934e-02,  7.0494e-02,\n",
              "          -7.4497e-02,  1.4436e-02, -5.1857e-03,  7.7257e-02,  2.4613e-02,\n",
              "          -2.3095e-02, -4.3948e-03,  1.7421e-02, -3.5985e-02,  1.2784e-02,\n",
              "          -6.0356e-02, -1.7307e-02, -2.0917e-03,  3.3032e-02, -6.1410e-02,\n",
              "           7.9608e-02,  2.7768e-02, -3.4363e-02, -6.1100e-02, -3.1468e-02,\n",
              "          -3.9813e-02,  3.5793e-02,  2.9954e-03,  1.8687e-02, -7.1464e-02,\n",
              "           1.8687e-02,  6.9480e-02,  8.6372e-02, -5.5390e-02,  1.6557e-02,\n",
              "           1.9878e-02,  8.0226e-02, -2.1137e-02,  9.2464e-02, -2.0413e-02,\n",
              "          -9.3492e-02,  9.0216e-02, -9.9643e-03, -4.5676e-02, -7.2762e-02,\n",
              "           9.5185e-02, -3.5671e-02, -5.7421e-02,  9.6054e-02, -1.0582e-02,\n",
              "           3.5247e-02,  4.4829e-04,  6.2995e-02, -7.0383e-02,  5.9155e-02,\n",
              "           9.5140e-02, -6.1451e-02,  7.1062e-02, -3.1055e-02,  6.2909e-02,\n",
              "           9.0056e-02, -5.9558e-02, -6.3497e-02, -7.2795e-02,  6.3794e-02,\n",
              "          -7.1646e-02, -5.9375e-03,  9.2007e-02, -2.3524e-02,  6.7093e-02,\n",
              "          -9.6363e-02,  8.5956e-02, -5.4083e-02,  4.6875e-02, -7.0707e-02],\n",
              "         [-9.9884e-02, -2.0566e-03, -9.2505e-03,  1.2660e-05,  5.7482e-02,\n",
              "           9.8647e-02,  5.9621e-02, -5.6918e-02, -2.3541e-02,  8.5597e-02,\n",
              "           3.2887e-02, -1.2115e-02,  6.3024e-02, -4.1736e-03,  1.5560e-02,\n",
              "          -3.6098e-02, -2.9918e-02,  9.7293e-02, -3.3788e-02,  6.5262e-02,\n",
              "          -6.2560e-03,  8.2679e-02, -3.4145e-02, -4.2508e-02,  9.3023e-02,\n",
              "           1.6028e-02, -7.6950e-02,  6.5384e-02,  6.1429e-02,  7.9440e-02,\n",
              "          -2.2314e-02, -8.0422e-02, -2.0729e-02, -4.6973e-02, -8.5903e-02,\n",
              "           8.3461e-02,  5.4504e-03,  6.4838e-02, -4.3093e-02, -1.4715e-02,\n",
              "           9.2161e-02, -1.6137e-02,  4.7117e-02,  4.8628e-02,  4.7408e-02,\n",
              "          -9.9202e-02, -9.7989e-02,  4.2185e-02,  6.1507e-02,  9.3029e-02,\n",
              "           2.3039e-02, -8.1951e-02,  4.2035e-02,  5.3145e-02,  1.7351e-02,\n",
              "           2.6871e-02,  3.6373e-02, -4.5585e-02, -7.1108e-02, -6.8185e-03,\n",
              "          -8.1368e-02,  4.8340e-02,  1.8260e-02, -7.0928e-02, -3.2509e-02,\n",
              "           3.3479e-02, -8.1458e-02,  7.4082e-03,  7.0904e-02, -8.2055e-02,\n",
              "          -4.5267e-02, -9.7422e-02,  6.2716e-02,  3.1780e-02,  2.6002e-02,\n",
              "           3.5429e-02, -2.8131e-02, -7.5722e-02,  8.6744e-02,  6.9950e-02,\n",
              "          -4.4811e-03, -3.7405e-02,  8.7347e-02,  2.9528e-02,  2.4509e-02,\n",
              "          -7.9858e-02,  1.0490e-03,  8.5361e-02, -6.4963e-03,  8.6767e-02,\n",
              "           1.9172e-03, -4.7197e-02, -9.4302e-02, -1.1154e-04,  4.4796e-02,\n",
              "           9.0297e-02, -4.5391e-02, -8.2952e-03, -8.3752e-04,  1.0406e-02],\n",
              "         [-8.3833e-02, -1.6800e-02, -1.8120e-02,  2.4787e-02,  1.5949e-02,\n",
              "          -3.6587e-02, -4.0931e-02, -2.8362e-02, -6.2916e-02,  9.5074e-04,\n",
              "           3.7527e-02, -7.5627e-02, -9.0116e-02, -4.8229e-02,  4.8008e-02,\n",
              "          -8.3595e-02, -7.4236e-02, -7.7821e-02, -6.1297e-02, -1.0876e-02,\n",
              "          -7.7140e-02,  9.9012e-02, -5.8988e-02,  9.1224e-02,  8.5215e-02,\n",
              "          -6.2058e-02, -9.7728e-02,  6.1797e-02,  8.5920e-02, -4.6782e-02,\n",
              "           4.5797e-02, -3.4127e-02, -2.6734e-02,  5.0654e-02,  8.0230e-02,\n",
              "          -6.8283e-04,  4.4868e-02,  9.9643e-02, -7.7270e-03, -6.9289e-03,\n",
              "           7.8843e-02, -6.2620e-02,  4.6331e-02,  3.5543e-02,  4.4476e-02,\n",
              "           6.4701e-02,  5.5111e-02, -1.3538e-02, -5.7666e-02,  3.1949e-02,\n",
              "          -7.4435e-02, -1.0555e-02, -2.9269e-02,  7.6828e-02,  6.0613e-02,\n",
              "          -1.0246e-02, -7.7053e-02, -8.1615e-02,  7.8583e-02, -3.7298e-02,\n",
              "           9.8287e-02, -8.7990e-02,  8.5202e-02,  7.3779e-02, -7.5497e-02,\n",
              "          -5.0194e-02,  1.7486e-02, -8.1503e-02,  4.3283e-02,  3.1912e-02,\n",
              "           3.3300e-02,  8.4082e-02, -1.5393e-02, -1.0400e-02, -5.7354e-02,\n",
              "           6.4003e-02,  7.5777e-02,  8.7583e-02,  1.0506e-02, -1.0069e-02,\n",
              "           4.6248e-02,  6.8776e-02,  9.1238e-02,  8.2242e-02, -6.3215e-02,\n",
              "          -2.2493e-03,  5.6948e-02, -1.4380e-02,  9.5676e-02,  9.8546e-02,\n",
              "           3.5439e-02, -6.1159e-02, -3.4391e-02,  4.1154e-02, -4.9081e-02,\n",
              "          -8.1823e-02, -1.6583e-02, -7.9054e-02, -8.9295e-02,  6.5986e-02],\n",
              "         [-4.6052e-02, -5.7329e-02, -6.9434e-02,  8.0967e-02, -1.9942e-02,\n",
              "          -5.2907e-02,  3.7663e-03, -6.5540e-02,  7.4881e-03, -7.2165e-02,\n",
              "          -5.0907e-03,  5.9958e-02,  7.3126e-02,  7.8212e-02,  9.5219e-02,\n",
              "          -5.8539e-02, -5.7033e-02,  5.0800e-02,  2.9198e-02,  5.7162e-02,\n",
              "           5.8643e-02,  2.4181e-02,  9.6798e-02, -7.2006e-02, -4.8288e-02,\n",
              "           9.8164e-02, -1.4304e-02,  8.4005e-02, -4.1074e-02,  4.0151e-03,\n",
              "          -2.9527e-02,  8.0418e-02,  4.4058e-02,  1.3534e-02,  2.5140e-02,\n",
              "           2.1768e-02, -9.8031e-02, -6.6325e-02, -3.6608e-02,  2.1682e-02,\n",
              "           8.6108e-02, -5.5307e-02,  2.1730e-02,  2.3178e-02, -2.4123e-02,\n",
              "          -6.6951e-03, -7.9058e-02,  8.1677e-02, -1.8746e-02, -3.1030e-02,\n",
              "           1.0893e-02, -5.3572e-02, -6.3206e-02, -2.8532e-02,  4.3749e-02,\n",
              "          -5.8695e-02,  9.5919e-03, -9.0220e-03,  6.0012e-02, -5.8548e-03,\n",
              "          -1.3501e-02,  7.4022e-02, -9.2908e-02, -1.4278e-02,  5.1928e-02,\n",
              "          -9.1766e-02,  7.3883e-02,  9.7954e-02,  2.0665e-02, -4.6826e-02,\n",
              "           3.8851e-02, -3.2427e-02, -2.0750e-02, -6.1963e-02, -6.8082e-02,\n",
              "           5.1893e-02,  7.8080e-02,  2.3663e-02,  9.9957e-02, -1.9962e-02,\n",
              "          -8.7717e-02, -5.7643e-02,  6.9828e-02,  1.4412e-02,  4.3624e-02,\n",
              "          -6.7853e-02, -8.7193e-02, -7.1548e-02, -5.8304e-02,  9.1487e-02,\n",
              "           8.0201e-02, -3.5304e-02,  5.6775e-02,  8.3264e-02,  6.6919e-02,\n",
              "           3.7993e-02,  5.4683e-03, -3.5126e-02,  6.6001e-03,  2.9616e-02],\n",
              "         [ 9.1658e-02,  9.4709e-02,  1.5736e-02,  2.2302e-02,  4.6048e-02,\n",
              "           1.2184e-02,  4.9628e-03,  7.0882e-02, -1.3095e-03,  6.4723e-02,\n",
              "           7.9142e-02,  1.6253e-02, -1.9196e-02,  4.3337e-02, -5.8832e-02,\n",
              "          -3.2178e-02, -6.3990e-02,  4.7409e-02, -2.7614e-02,  1.7234e-02,\n",
              "          -1.0813e-02, -1.4974e-02,  2.3524e-02,  8.9089e-02, -3.2056e-02,\n",
              "           7.2992e-02, -6.9731e-02,  8.7564e-02, -8.0852e-02, -6.2523e-02,\n",
              "          -7.4421e-02,  4.1387e-02, -7.6536e-02, -4.0783e-02, -6.2073e-02,\n",
              "          -1.3144e-03,  7.2717e-02,  8.8049e-02,  9.7246e-03,  7.4112e-02,\n",
              "          -8.7396e-02,  2.9497e-02,  5.1279e-02, -7.4738e-02, -3.1917e-02,\n",
              "           4.6675e-02, -5.1561e-02, -6.6640e-03,  6.4942e-03,  7.4746e-02,\n",
              "           9.1743e-02,  2.8841e-02, -1.4908e-02, -7.4951e-02,  6.2403e-03,\n",
              "           2.7113e-02, -5.0571e-02,  1.4710e-02,  6.0440e-02, -7.6236e-02,\n",
              "           9.0964e-02,  4.2240e-02, -6.1111e-03, -2.5226e-02,  3.2602e-02,\n",
              "          -7.5661e-02,  8.3860e-03, -4.4427e-02, -6.7322e-02,  4.4364e-02,\n",
              "           5.9016e-02,  8.1961e-02,  3.3115e-02, -4.0448e-02, -7.3765e-02,\n",
              "           9.2396e-02, -4.5676e-02,  9.7899e-02,  3.1652e-02, -9.1355e-03,\n",
              "          -7.1571e-02, -1.3682e-02,  7.2462e-02, -4.6750e-02,  6.0865e-02,\n",
              "          -4.6380e-02, -8.9269e-02,  6.8284e-02,  3.6599e-02, -4.0685e-02,\n",
              "           5.8471e-02,  7.1903e-02,  4.0558e-02,  8.0305e-02,  8.1107e-02,\n",
              "          -8.6739e-02, -9.7542e-02,  6.3673e-02, -9.2271e-02, -1.9315e-02],\n",
              "         [-4.6198e-02, -3.2290e-02, -3.0544e-02, -9.5010e-02,  3.8223e-02,\n",
              "           5.5294e-02,  4.9098e-02,  7.6608e-02, -8.0285e-02,  6.2018e-02,\n",
              "          -5.3086e-02,  3.0058e-02, -2.2902e-03, -6.1048e-03, -4.9441e-02,\n",
              "          -5.9305e-02,  3.3375e-03,  3.5207e-02,  6.2350e-02, -4.4059e-02,\n",
              "          -8.4517e-04, -8.6304e-02,  5.4937e-02, -6.0786e-02,  3.9300e-02,\n",
              "          -7.0746e-03,  7.5575e-03,  1.6690e-02,  9.7747e-02, -9.1711e-02,\n",
              "           6.9647e-02, -4.7292e-02,  6.8328e-02,  7.7011e-02, -1.1921e-02,\n",
              "           8.2020e-02,  8.4751e-02,  3.6825e-03,  9.3275e-02, -2.9666e-02,\n",
              "          -9.1267e-02, -8.1389e-02,  3.3100e-02,  6.4213e-02,  8.2357e-02,\n",
              "           5.5568e-02,  6.8318e-02, -1.3603e-02,  2.9641e-04,  8.3104e-02,\n",
              "          -2.4244e-02,  4.1599e-02, -2.7592e-02, -4.9556e-02,  5.1370e-02,\n",
              "          -9.9622e-02,  4.8358e-02, -3.7282e-04, -7.3551e-03, -6.0729e-02,\n",
              "           9.5725e-02,  1.6859e-02,  1.2552e-02,  8.2822e-02, -5.8674e-03,\n",
              "           6.0212e-02,  9.1049e-02, -4.2251e-02,  9.4969e-04,  9.7892e-02,\n",
              "          -5.9672e-02,  6.4663e-02, -6.1649e-02, -7.8423e-02, -9.9728e-02,\n",
              "           1.5248e-02,  7.8801e-03,  4.2608e-03,  1.0335e-02, -9.8835e-02,\n",
              "          -2.1486e-02, -5.8640e-03, -5.1451e-02,  2.8623e-02,  7.4678e-02,\n",
              "           5.7444e-02, -9.5587e-04,  9.2813e-02, -8.9171e-02,  6.2987e-02,\n",
              "           4.5349e-02,  3.2147e-02,  6.9089e-02,  9.8212e-02,  9.4147e-02,\n",
              "          -9.4832e-02,  8.1579e-02, -7.1328e-02, -1.0579e-02,  2.5450e-02],\n",
              "         [-2.0891e-02, -6.0200e-03,  2.5615e-02, -1.7990e-02, -4.4823e-02,\n",
              "           2.3133e-02,  2.7158e-02, -2.7425e-02, -8.8589e-02,  5.5512e-03,\n",
              "          -6.2966e-02,  8.8285e-02,  1.2188e-02,  3.6578e-02,  6.4057e-02,\n",
              "           2.6910e-02,  8.8557e-02, -4.2429e-02, -4.2300e-02, -8.4609e-02,\n",
              "           7.7359e-02,  4.4733e-02, -5.5614e-03,  2.1624e-02,  4.7043e-02,\n",
              "          -8.8673e-02,  1.0857e-03, -9.5129e-02,  6.8912e-02, -2.1803e-02,\n",
              "           2.6299e-02, -5.5845e-02,  2.7732e-02, -1.0555e-02, -4.8043e-02,\n",
              "          -5.9004e-02,  7.6596e-02, -6.0483e-02, -7.3551e-02, -6.5031e-02,\n",
              "           2.0799e-02, -7.2074e-02, -4.2507e-02,  5.0316e-02,  7.6159e-02,\n",
              "           3.6825e-02,  1.6714e-02, -9.0212e-02,  1.8672e-02,  2.7955e-02,\n",
              "          -1.2733e-02, -4.5933e-02,  5.4120e-02, -1.3092e-02, -8.3096e-02,\n",
              "           7.8286e-02,  8.5046e-02,  8.6231e-02,  2.0992e-02,  1.5767e-02,\n",
              "          -3.1872e-02,  5.8948e-02, -1.4357e-02,  5.2033e-02,  3.7963e-02,\n",
              "           5.1407e-02, -7.3431e-02,  5.3929e-02,  2.0105e-02,  9.9624e-02,\n",
              "          -1.7876e-02,  6.0013e-02, -5.3841e-02, -3.8886e-02, -3.2458e-02,\n",
              "           2.0245e-02, -1.2786e-02, -7.3796e-02, -5.1257e-02, -9.3105e-02,\n",
              "           5.3524e-02,  2.9062e-02,  6.2409e-02,  1.5023e-02,  5.3282e-02,\n",
              "           6.6994e-02,  5.3158e-02, -8.6123e-02, -8.5278e-02,  6.5582e-02,\n",
              "          -4.3465e-02,  4.4255e-02, -4.5839e-02,  5.9404e-02,  6.6008e-02,\n",
              "           6.7964e-02, -2.4449e-02, -7.3628e-02,  8.2040e-02,  7.7660e-02],\n",
              "         [-9.8090e-02,  2.3876e-02, -8.2799e-02, -7.0161e-02,  1.3677e-02,\n",
              "           6.1290e-02, -4.8976e-04, -2.8927e-03,  6.0759e-02, -8.4032e-03,\n",
              "          -3.1913e-02,  7.0797e-02,  8.9694e-02,  7.0325e-02,  6.5696e-02,\n",
              "          -1.5075e-02, -6.6608e-02,  7.0226e-02, -9.6515e-02, -1.0970e-02,\n",
              "          -7.4666e-02,  2.0471e-03,  7.9205e-02, -5.1160e-02, -8.5243e-02,\n",
              "          -8.7755e-02, -4.8625e-02,  6.3410e-02,  4.8973e-02, -3.0467e-02,\n",
              "           5.1149e-02, -6.8542e-04, -5.4671e-02,  7.0579e-02, -1.1052e-02,\n",
              "           3.7288e-02,  1.3069e-03,  6.5359e-02, -4.5996e-02,  1.3190e-03,\n",
              "           7.8334e-02, -3.5620e-02, -9.9353e-02, -3.0465e-03, -6.0722e-02,\n",
              "          -9.8107e-02, -3.9692e-02,  9.0779e-02, -2.8267e-02, -9.7357e-02,\n",
              "           6.7107e-02,  1.4171e-02,  6.0091e-02, -4.2909e-03,  6.2227e-02,\n",
              "           2.0596e-02, -9.5249e-03,  7.1651e-02, -9.0290e-02,  5.0313e-02,\n",
              "           7.2475e-02, -7.2112e-02,  8.7810e-02, -8.1037e-02, -2.8049e-02,\n",
              "           7.4033e-02, -6.5308e-02,  9.4824e-02, -7.8563e-03,  2.1731e-02,\n",
              "           5.2775e-02,  3.0641e-03, -5.3218e-02,  6.5832e-02,  6.4242e-03,\n",
              "           7.5386e-02,  9.0389e-02,  3.9998e-02, -7.2098e-03,  4.1883e-02,\n",
              "          -6.8180e-03, -3.5155e-02,  8.9635e-02, -3.1142e-02,  5.8973e-02,\n",
              "           9.9291e-02, -6.8097e-02, -7.9742e-02, -6.8372e-02,  7.2811e-02,\n",
              "           9.2736e-02, -5.7095e-02,  3.8777e-02, -2.4662e-03, -4.7575e-02,\n",
              "          -4.8032e-02, -2.5639e-02,  7.4412e-02, -8.6548e-02, -4.4684e-02]],\n",
              "        device='cuda:0', requires_grad=True), Parameter containing:\n",
              " tensor([ 0.0935, -0.0211, -0.0509,  0.0983,  0.0549,  0.0581, -0.0937, -0.0555,\n",
              "          0.0050, -0.0360], device='cuda:0', requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "93278bb1-9072-4b46-9611-90efebb7cf93",
      "metadata": {
        "id": "93278bb1-9072-4b46-9611-90efebb7cf93"
      },
      "outputs": [],
      "source": [
        "loss = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(mnist_net.parameters(), lr=1.0e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "d57e448f-4eb8-4f52-8324-bc93e4a8a3e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d57e448f-4eb8-4f52-8324-bc93e4a8a3e0",
        "outputId": "f58ea933-6847-494a-9a4d-086736d9cee2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.9596, device='cuda:0')\n",
            "tensor(0.9575, device='cuda:0')\n",
            "tensor(0.9574, device='cuda:0')\n",
            "tensor(0.9575, device='cuda:0')\n",
            "tensor(0.9556, device='cuda:0')\n",
            "tensor(0.9550, device='cuda:0')\n",
            "tensor(0.9553, device='cuda:0')\n",
            "tensor(0.9563, device='cuda:0')\n",
            "tensor(0.9592, device='cuda:0')\n",
            "tensor(0.9599, device='cuda:0')\n",
            "tensor(0.9584, device='cuda:0')\n",
            "tensor(0.9556, device='cuda:0')\n",
            "tensor(0.9599, device='cuda:0')\n",
            "tensor(0.9533, device='cuda:0')\n",
            "tensor(0.9602, device='cuda:0')\n",
            "tensor(0.9596, device='cuda:0')\n",
            "tensor(0.9580, device='cuda:0')\n",
            "tensor(0.9599, device='cuda:0')\n",
            "tensor(0.9601, device='cuda:0')\n",
            "tensor(0.9582, device='cuda:0')\n",
            "tensor(0.9591, device='cuda:0')\n",
            "tensor(0.9579, device='cuda:0')\n",
            "tensor(0.9600, device='cuda:0')\n",
            "tensor(0.9596, device='cuda:0')\n",
            "tensor(0.9571, device='cuda:0')\n",
            "tensor(0.9617, device='cuda:0')\n",
            "tensor(0.9622, device='cuda:0')\n",
            "tensor(0.9608, device='cuda:0')\n",
            "tensor(0.9561, device='cuda:0')\n",
            "tensor(0.9586, device='cuda:0')\n",
            "tensor(0.9594, device='cuda:0')\n",
            "tensor(0.9605, device='cuda:0')\n",
            "tensor(0.9581, device='cuda:0')\n",
            "tensor(0.9600, device='cuda:0')\n",
            "tensor(0.9603, device='cuda:0')\n",
            "tensor(0.9599, device='cuda:0')\n",
            "tensor(0.9588, device='cuda:0')\n",
            "tensor(0.9621, device='cuda:0')\n",
            "tensor(0.9606, device='cuda:0')\n",
            "tensor(0.9607, device='cuda:0')\n",
            "tensor(0.9613, device='cuda:0')\n",
            "tensor(0.9616, device='cuda:0')\n",
            "tensor(0.9612, device='cuda:0')\n",
            "tensor(0.9586, device='cuda:0')\n",
            "tensor(0.9590, device='cuda:0')\n",
            "tensor(0.9627, device='cuda:0')\n",
            "tensor(0.9619, device='cuda:0')\n",
            "tensor(0.9605, device='cuda:0')\n",
            "tensor(0.9610, device='cuda:0')\n",
            "tensor(0.9606, device='cuda:0')\n",
            "tensor(0.9600, device='cuda:0')\n",
            "tensor(0.9593, device='cuda:0')\n",
            "tensor(0.9577, device='cuda:0')\n",
            "tensor(0.9556, device='cuda:0')\n",
            "tensor(0.9601, device='cuda:0')\n",
            "tensor(0.9584, device='cuda:0')\n",
            "tensor(0.9610, device='cuda:0')\n",
            "tensor(0.9629, device='cuda:0')\n",
            "tensor(0.9620, device='cuda:0')\n",
            "tensor(0.9606, device='cuda:0')\n",
            "tensor(0.9609, device='cuda:0')\n",
            "tensor(0.9600, device='cuda:0')\n",
            "tensor(0.9627, device='cuda:0')\n",
            "tensor(0.9634, device='cuda:0')\n",
            "tensor(0.9614, device='cuda:0')\n",
            "tensor(0.9624, device='cuda:0')\n",
            "tensor(0.9646, device='cuda:0')\n",
            "tensor(0.9646, device='cuda:0')\n",
            "tensor(0.9623, device='cuda:0')\n",
            "tensor(0.9605, device='cuda:0')\n",
            "tensor(0.9635, device='cuda:0')\n",
            "tensor(0.9601, device='cuda:0')\n",
            "tensor(0.9604, device='cuda:0')\n",
            "tensor(0.9606, device='cuda:0')\n",
            "tensor(0.9634, device='cuda:0')\n",
            "tensor(0.9620, device='cuda:0')\n",
            "tensor(0.9628, device='cuda:0')\n",
            "tensor(0.9627, device='cuda:0')\n",
            "tensor(0.9641, device='cuda:0')\n",
            "tensor(0.9650, device='cuda:0')\n",
            "tensor(0.9638, device='cuda:0')\n",
            "tensor(0.9617, device='cuda:0')\n",
            "tensor(0.9617, device='cuda:0')\n",
            "tensor(0.9648, device='cuda:0')\n",
            "tensor(0.9638, device='cuda:0')\n",
            "tensor(0.9652, device='cuda:0')\n",
            "tensor(0.9638, device='cuda:0')\n",
            "tensor(0.9619, device='cuda:0')\n",
            "tensor(0.9609, device='cuda:0')\n",
            "tensor(0.9638, device='cuda:0')\n",
            "tensor(0.9628, device='cuda:0')\n",
            "tensor(0.9650, device='cuda:0')\n",
            "tensor(0.9633, device='cuda:0')\n",
            "tensor(0.9640, device='cuda:0')\n",
            "tensor(0.9642, device='cuda:0')\n",
            "tensor(0.9634, device='cuda:0')\n",
            "tensor(0.9625, device='cuda:0')\n",
            "tensor(0.9634, device='cuda:0')\n",
            "tensor(0.9631, device='cuda:0')\n",
            "tensor(0.9623, device='cuda:0')\n",
            "working time = 109.70612931251526\n"
          ]
        }
      ],
      "source": [
        "from time import time\n",
        "batch_size = 100\n",
        "test_accuracy_history = []\n",
        "test_loss_history = []\n",
        "\n",
        "X_test = X_test.to(device)\n",
        "y_test = y_test.to(device)\n",
        "\n",
        "start_time = time()\n",
        "for epoch in range(100):\n",
        "    order = np.random.permutation(len(X_train))\n",
        "    \n",
        "    for start_index in range(0, len(X_train), batch_size):\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        batch_indexes = order[start_index:start_index+batch_size]\n",
        "        \n",
        "        X_batch = X_train[batch_indexes].to(device)\n",
        "        y_batch = y_train[batch_indexes].to(device)\n",
        "        \n",
        "        preds = mnist_net.forward(X_batch) \n",
        "        \n",
        "        loss_value = loss(preds, y_batch)\n",
        "        loss_value.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "\n",
        "    test_preds = mnist_net.forward(X_test)\n",
        "    test_loss_history.append(loss(test_preds, y_test))\n",
        "    \n",
        "    accuracy = (test_preds.argmax(dim=1) == y_test).float().mean()\n",
        "    test_accuracy_history.append(accuracy)\n",
        "    print(accuracy)\n",
        "finish_time = time()\n",
        "print('working time = '+ str(finish_time - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_net2 = MNISTNet(100)\n",
        "device = torch.device('cpu')\n",
        "mnist_net2 = mnist_net2.to(device)"
      ],
      "metadata": {
        "id": "T0Nz_FiG5mVI"
      },
      "id": "T0Nz_FiG5mVI",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = torch.nn.CrossEntropyLoss()\n",
        "optimizer2 = torch.optim.Adam(mnist_net2.parameters(), lr=1.0e-3)"
      ],
      "metadata": {
        "id": "peQ37lyk6yty"
      },
      "id": "peQ37lyk6yty",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "test_accuracy_history = []\n",
        "test_loss_history = []\n",
        "\n",
        "X_test = X_test.to(device)\n",
        "y_test = y_test.to(device)\n",
        "\n",
        "start_time = time()\n",
        "for epoch in range(100):\n",
        "    order = np.random.permutation(len(X_train))\n",
        "    \n",
        "    for start_index in range(0, len(X_train), batch_size):\n",
        "        optimizer2.zero_grad()\n",
        "        \n",
        "        batch_indexes = order[start_index:start_index+batch_size]\n",
        "        \n",
        "        X_batch = X_train[batch_indexes].to(device)\n",
        "        y_batch = y_train[batch_indexes].to(device)\n",
        "        \n",
        "        preds = mnist_net2.forward(X_batch) \n",
        "        \n",
        "        loss_value = loss(preds, y_batch)\n",
        "        loss_value.backward()\n",
        "        \n",
        "        optimizer2.step()\n",
        "\n",
        "    test_preds = mnist_net2.forward(X_test)\n",
        "    test_loss_history.append(loss(test_preds, y_test))\n",
        "    \n",
        "    accuracy = (test_preds.argmax(dim=1) == y_test).float().mean()\n",
        "    test_accuracy_history.append(accuracy)\n",
        "    print(accuracy)\n",
        "finish_time = time()\n",
        "print('working time = '+ str(finish_time - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRx1vP0C64Il",
        "outputId": "bc348f0c-eb38-4249-c913-7f920c2e2d7f"
      },
      "id": "SRx1vP0C64Il",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.9095)\n",
            "tensor(0.9154)\n",
            "tensor(0.9186)\n",
            "tensor(0.9261)\n",
            "tensor(0.9258)\n",
            "tensor(0.9266)\n",
            "tensor(0.9306)\n",
            "tensor(0.9304)\n",
            "tensor(0.9309)\n",
            "tensor(0.9316)\n",
            "tensor(0.9361)\n",
            "tensor(0.9366)\n",
            "tensor(0.9400)\n",
            "tensor(0.9401)\n",
            "tensor(0.9395)\n",
            "tensor(0.9377)\n",
            "tensor(0.9369)\n",
            "tensor(0.9398)\n",
            "tensor(0.9379)\n",
            "tensor(0.9365)\n",
            "tensor(0.9407)\n",
            "tensor(0.9443)\n",
            "tensor(0.9394)\n",
            "tensor(0.9395)\n",
            "tensor(0.9354)\n",
            "tensor(0.9472)\n",
            "tensor(0.9419)\n",
            "tensor(0.9417)\n",
            "tensor(0.9454)\n",
            "tensor(0.9448)\n",
            "tensor(0.9471)\n",
            "tensor(0.9454)\n",
            "tensor(0.9499)\n",
            "tensor(0.9446)\n",
            "tensor(0.9446)\n",
            "tensor(0.9424)\n",
            "tensor(0.9469)\n",
            "tensor(0.9475)\n",
            "tensor(0.9505)\n",
            "tensor(0.9529)\n",
            "tensor(0.9479)\n",
            "tensor(0.9506)\n",
            "tensor(0.9478)\n",
            "tensor(0.9468)\n",
            "tensor(0.9496)\n",
            "tensor(0.9506)\n",
            "tensor(0.9478)\n",
            "tensor(0.9483)\n",
            "tensor(0.9474)\n",
            "tensor(0.9501)\n",
            "tensor(0.9537)\n",
            "tensor(0.9553)\n",
            "tensor(0.9479)\n",
            "tensor(0.9526)\n",
            "tensor(0.9541)\n",
            "tensor(0.9564)\n",
            "tensor(0.9530)\n",
            "tensor(0.9525)\n",
            "tensor(0.9552)\n",
            "tensor(0.9488)\n",
            "tensor(0.9534)\n",
            "tensor(0.9523)\n",
            "tensor(0.9516)\n",
            "tensor(0.9490)\n",
            "tensor(0.9550)\n",
            "tensor(0.9541)\n",
            "tensor(0.9518)\n",
            "tensor(0.9552)\n",
            "tensor(0.9552)\n",
            "tensor(0.9550)\n",
            "tensor(0.9551)\n",
            "tensor(0.9556)\n",
            "tensor(0.9540)\n",
            "tensor(0.9516)\n",
            "tensor(0.9584)\n",
            "tensor(0.9544)\n",
            "tensor(0.9568)\n",
            "tensor(0.9531)\n",
            "tensor(0.9568)\n",
            "tensor(0.9557)\n",
            "tensor(0.9576)\n",
            "tensor(0.9554)\n",
            "tensor(0.9527)\n",
            "tensor(0.9577)\n",
            "tensor(0.9563)\n",
            "tensor(0.9530)\n",
            "tensor(0.9556)\n",
            "tensor(0.9553)\n",
            "tensor(0.9528)\n",
            "tensor(0.9559)\n",
            "tensor(0.9532)\n",
            "tensor(0.9594)\n",
            "tensor(0.9567)\n",
            "tensor(0.9555)\n",
            "tensor(0.9577)\n",
            "tensor(0.9599)\n",
            "tensor(0.9588)\n",
            "tensor(0.9595)\n",
            "tensor(0.9579)\n",
            "tensor(0.9553)\n",
            "working time = 191.228764295578\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "Lab3.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}